{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataframe = pd.read_csv(\"./data/text/training_data_50000.csv\")\n",
    "epochs = 10\n",
    "vec_size = 50\n",
    "num_cores = 4\n",
    "pred_to_context_word_dist_thresh = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docLabels = list(training_dataframe[\"Index\"])\n",
    "sentimentLabels = np.array(training_dataframe[\"Sentiment\"])\n",
    "data = list(training_dataframe[\"SentimentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield LabeledSentence(words=doc.split(),tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = LabeledLineSentence(data, docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done for epoch :  0\n",
      "Training done for epoch :  1\n",
      "Training done for epoch :  2\n",
      "Training done for epoch :  3\n",
      "Training done for epoch :  4\n",
      "Training done for epoch :  5\n",
      "Training done for epoch :  6\n",
      "Training done for epoch :  7\n",
      "Training done for epoch :  8\n",
      "Training done for epoch :  9\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(size=vec_size,window=pred_to_context_word_dist_thresh,workers=num_cores,alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "model.build_vocab(sentences)\n",
    "for epoch in range(10):\n",
    "    print(\"Training done for epoch : \",epoch)\n",
    "    model.train(sentences=sentences)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no deca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.empty((len(training_dataframe),vec_size))\n",
    "train_label = sentimentLabels\n",
    "for i in range(len(training_dataframe)):\n",
    "    train_data[i] = model.docvecs[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21240686,  0.04456875, -0.23503773, ..., -0.1962624 ,\n",
       "        -0.1204211 , -0.07198631],\n",
       "       [ 0.0300697 , -0.11546917, -0.37795967, ..., -0.13256611,\n",
       "         0.31415638,  0.19001837],\n",
       "       [-1.04692352,  0.24685332,  0.27830318, ...,  0.17234065,\n",
       "        -0.01301328,  0.09401999],\n",
       "       ..., \n",
       "       [-0.55868679, -0.01660823, -0.72503167, ...,  0.72931635,\n",
       "         0.41534641, -0.531416  ],\n",
       "       [-0.65339279, -0.14587922, -0.86026508, ..., -0.28859982,\n",
       "         0.02004016, -0.04188761],\n",
       "       [ 0.00586572, -0.00149885,  0.00684214, ..., -0.00207298,\n",
       "        -0.00182077,  0.00462301]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dict = dict()\n",
    "train_data_dict[\"data\"] = train_data.tolist()\n",
    "train_data_dict[\"label\"] = train_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train_data_50000.json', 'w') as fp:\n",
    "    json.dump(train_data_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
